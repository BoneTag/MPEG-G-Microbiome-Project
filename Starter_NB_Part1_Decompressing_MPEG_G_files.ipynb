{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "f757ef79-0473-4c17-a9f8-79c20633dc87",
      "metadata": {
        "id": "f757ef79-0473-4c17-a9f8-79c20633dc87"
      },
      "source": [
        "# 🧠 Part 1: The Plan for unzipping the Train and Test folders and view the MPEG-G files\n",
        "We’ll create a local Jupyter notebook or script that:\n",
        "\n",
        "0. 🔧 Step 0: Prerequisites\n",
        "1. 🐳 Pulls and runs the Genie Docker container\n",
        "2. 📤 Extract the Train and Test File from TrainFiles.zip and TestFiles.zip\n",
        "3. 🐳 Pull the Genie Docker Image\n",
        "4. 📂 Mounts your ```.mgb``` file for one file in TrainFiles.\n",
        "5. 🧬 Load FASTQ in Python\n",
        "6. 💡 Explain the layers and outputs in plain English for a data scientist unfamiliar with bioinformatics\n",
        "7. 🏃 Run steps 4 & 5 for all files in TrainFiles and TestFiles\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4f6c544b-60de-4a99-b562-1801718423b4",
      "metadata": {
        "id": "4f6c544b-60de-4a99-b562-1801718423b4"
      },
      "source": [
        "## 📓 Let’s Start with a Local Notebook\n",
        "Here's how your local notebook should look:"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ba1c3f32-5008-443a-92ef-cda803562cb5",
      "metadata": {
        "jp-MarkdownHeadingCollapsed": true,
        "id": "ba1c3f32-5008-443a-92ef-cda803562cb5"
      },
      "source": [
        "### 🔧 Step 0: Prerequisites\n",
        "\n",
        "1. Install an Integrated Development environment VSCode or Anaconda\n",
        "2. Install Docker (if you haven’t already):\n",
        "👉 https://www.docker.com/products/docker-desktop/\n",
        "3. Install Python\n",
        "4. Install Conda\n",
        "5. Create a virtual invironment\n",
        "\n",
        "Note: doing this you may be asked to install command line tools depending on your machine, xcode, git, etc, but it is worth it as you will find them useful. Some of the downloads may take more than half an hour, stay focused and follow instructions.\n",
        "\n",
        " Instructions for Mac are available [here](https://docs.google.com/document/d/1Rug61nxs6FLqlYh8Qzqgzuv6nq3lyTq45HVB6cqERfE/edit?usp=sharing)  \n",
        "If you already have IDE, Python, CondaInstall Docker:\n",
        "👉 https://www.docker.com/products/docker-desktop/\n",
        "\n",
        "Important:\n",
        "\n",
        " However, we recommend that you install Biopython using conda, as it will also install the required dependencies.\n",
        "\n",
        "` conda install Bio`\n",
        "\n",
        " A better approach is to create a new conda environment for your project, and then install Biopython in that environment:\n",
        "\n",
        " `conda create -n myenv mpegg_env `\n",
        " Activate the environment\n",
        "\n",
        " `conda activate mpegg_env`\n",
        " Now you can install Biopython in the new environment  and then import Bio in your code\n",
        "\n",
        "` conda install -c conda-forge biopython`\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "02ad8d83-b7c2-4127-976d-a4830a656970",
      "metadata": {
        "id": "02ad8d83-b7c2-4127-976d-a4830a656970",
        "outputId": "0f2a2e96-bd38-44d9-e79b-8e6eded984c8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Hello from Docker!\n",
            "This message shows that your installation appears to be working correctly.\n",
            "\n",
            "To generate this message, Docker took the following steps:\n",
            " 1. The Docker client contacted the Docker daemon.\n",
            " 2. The Docker daemon pulled the \"hello-world\" image from the Docker Hub.\n",
            "    (amd64)\n",
            " 3. The Docker daemon created a new container from that image which runs the\n",
            "    executable that produces the output you are currently reading.\n",
            " 4. The Docker daemon streamed that output to the Docker client, which sent it\n",
            "    to your terminal.\n",
            "\n",
            "To try something more ambitious, you can run an Ubuntu container with:\n",
            " $ docker run -it ubuntu bash\n",
            "\n",
            "Share images, automate workflows, and more with a free Docker ID:\n",
            " https://hub.docker.com/\n",
            "\n",
            "For more examples and ideas, visit:\n",
            " https://docs.docker.com/get-started/\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Test Docker works\n",
        "!docker run hello-world"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2b575244-916f-4e82-8ab4-325dc13848f9",
      "metadata": {
        "id": "2b575244-916f-4e82-8ab4-325dc13848f9",
        "outputId": "ef82b582-8b4e-4da9-e61a-1088d6115ffc"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: Bio in c:\\users\\amyfl\\anaconda3\\lib\\site-packages (1.8.0)\n",
            "Requirement already satisfied: biopython>=1.80 in c:\\users\\amyfl\\anaconda3\\lib\\site-packages (from Bio) (1.85)\n",
            "Requirement already satisfied: gprofiler-official in c:\\users\\amyfl\\anaconda3\\lib\\site-packages (from Bio) (1.0.0)\n",
            "Requirement already satisfied: mygene in c:\\users\\amyfl\\anaconda3\\lib\\site-packages (from Bio) (3.2.2)\n",
            "Requirement already satisfied: pandas in c:\\users\\amyfl\\anaconda3\\lib\\site-packages (from Bio) (2.2.2)\n",
            "Requirement already satisfied: pooch in c:\\users\\amyfl\\anaconda3\\lib\\site-packages (from Bio) (1.8.2)\n",
            "Requirement already satisfied: requests in c:\\users\\amyfl\\anaconda3\\lib\\site-packages (from Bio) (2.32.2)\n",
            "Requirement already satisfied: tqdm in c:\\users\\amyfl\\anaconda3\\lib\\site-packages (from Bio) (4.66.4)\n",
            "Requirement already satisfied: numpy in c:\\users\\amyfl\\anaconda3\\lib\\site-packages (from biopython>=1.80->Bio) (1.26.4)\n",
            "Requirement already satisfied: biothings-client>=0.2.6 in c:\\users\\amyfl\\anaconda3\\lib\\site-packages (from mygene->Bio) (0.4.1)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\amyfl\\anaconda3\\lib\\site-packages (from pandas->Bio) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in c:\\users\\amyfl\\anaconda3\\lib\\site-packages (from pandas->Bio) (2024.1)\n",
            "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\amyfl\\anaconda3\\lib\\site-packages (from pandas->Bio) (2023.3)\n",
            "Requirement already satisfied: platformdirs>=2.5.0 in c:\\users\\amyfl\\anaconda3\\lib\\site-packages (from pooch->Bio) (3.10.0)\n",
            "Requirement already satisfied: packaging>=20.0 in c:\\users\\amyfl\\anaconda3\\lib\\site-packages (from pooch->Bio) (23.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\amyfl\\anaconda3\\lib\\site-packages (from requests->Bio) (2.0.4)\n",
            "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\amyfl\\anaconda3\\lib\\site-packages (from requests->Bio) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\amyfl\\anaconda3\\lib\\site-packages (from requests->Bio) (2.2.2)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\amyfl\\anaconda3\\lib\\site-packages (from requests->Bio) (2024.7.4)\n",
            "Requirement already satisfied: colorama in c:\\users\\amyfl\\anaconda3\\lib\\site-packages (from tqdm->Bio) (0.4.6)\n",
            "Requirement already satisfied: httpx>=0.22.0 in c:\\users\\amyfl\\anaconda3\\lib\\site-packages (from biothings-client>=0.2.6->mygene->Bio) (0.27.0)\n",
            "Requirement already satisfied: six>=1.5 in c:\\users\\amyfl\\anaconda3\\lib\\site-packages (from python-dateutil>=2.8.2->pandas->Bio) (1.16.0)\n",
            "Requirement already satisfied: anyio in c:\\users\\amyfl\\anaconda3\\lib\\site-packages (from httpx>=0.22.0->biothings-client>=0.2.6->mygene->Bio) (4.2.0)\n",
            "Requirement already satisfied: httpcore==1.* in c:\\users\\amyfl\\anaconda3\\lib\\site-packages (from httpx>=0.22.0->biothings-client>=0.2.6->mygene->Bio) (1.0.2)\n",
            "Requirement already satisfied: sniffio in c:\\users\\amyfl\\anaconda3\\lib\\site-packages (from httpx>=0.22.0->biothings-client>=0.2.6->mygene->Bio) (1.3.0)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in c:\\users\\amyfl\\anaconda3\\lib\\site-packages (from httpcore==1.*->httpx>=0.22.0->biothings-client>=0.2.6->mygene->Bio) (0.14.0)\n"
          ]
        }
      ],
      "source": [
        "!pip install Bio"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d76e459f-00d9-4562-89b8-96b593b338bf",
      "metadata": {
        "id": "d76e459f-00d9-4562-89b8-96b593b338bf"
      },
      "outputs": [],
      "source": [
        "# Import packages\n",
        "import os\n",
        "import zipfile\n",
        "import subprocess\n",
        "import random\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import shutil\n",
        "\n",
        "\n",
        "from Bio import SeqIO\n",
        "from collections import Counter\n",
        "\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.metrics import classification_report\n",
        "\n",
        "# Errors ignore\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3016962c-4346-4c93-a98b-3a50a93a9fc6",
      "metadata": {
        "id": "3016962c-4346-4c93-a98b-3a50a93a9fc6"
      },
      "source": [
        "## Step 1. 📤 Extract the Train and Test File from a .zip"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(os.listdir('.'))"
      ],
      "metadata": {
        "id": "t589j2tflNVs"
      },
      "id": "t589j2tflNVs",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0d35c0ec-ca34-4702-bada-64928c1f4805",
      "metadata": {
        "id": "0d35c0ec-ca34-4702-bada-64928c1f4805",
        "outputId": "909045d7-daeb-4091-81d8-8678720d8f13"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "✅ Extracted TrainFiles.zip to ././/\n",
            "✅ Extracted TestFiles.zip to ././/\n"
          ]
        }
      ],
      "source": [
        "# Define your zip files and corresponding output directories\n",
        "zip_targets = {\n",
        "    'TrainFiles.zip': './',\n",
        "    'TestFiles.zip': './'\n",
        "}\n",
        "\n",
        "for zip_path, extract_to in zip_targets.items():\n",
        "    # Create the output directory if it doesn't exist\n",
        "    os.makedirs(extract_to, exist_ok=True)\n",
        "\n",
        "    # Extract zip content\n",
        "    with zipfile.ZipFile(zip_path, 'r') as zip_ref:\n",
        "        zip_ref.extractall(extract_to)\n",
        "        print(f\"✅ Extracted {zip_path} to ./{extract_to}/\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "17685824-7367-453c-8927-c42a1be05faa",
      "metadata": {
        "id": "17685824-7367-453c-8927-c42a1be05faa"
      },
      "source": [
        "## 🐳 Step 2: Pull the Genie Docker Image"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "665031c8-871b-4aff-a65c-a359d82af235",
      "metadata": {
        "id": "665031c8-871b-4aff-a65c-a359d82af235",
        "outputId": "0e6bf544-d52d-4cb5-816b-733f3f9dbde3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "latest: Pulling from muefab/genie\n",
            "Digest: sha256:c3112a3879cc18061bbab5ed8f76dec255ab1be46e2133cd59320dd5ba98ef89\n",
            "Status: Image is up to date for muefab/genie:latest\n",
            "docker.io/muefab/genie:latest\n"
          ]
        }
      ],
      "source": [
        "# Ensure you have the latest version of Genie\n",
        "!docker pull muefab/genie:latest"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "736a0714-fe8a-4965-8177-8df0556eb4ad",
      "metadata": {
        "id": "736a0714-fe8a-4965-8177-8df0556eb4ad"
      },
      "source": [
        "## 🏃 Steps 4 - 8 for one MPEG-G file"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "856fc2c5-98c5-4c49-b1a2-f5a71a64c763",
      "metadata": {
        "id": "856fc2c5-98c5-4c49-b1a2-f5a71a64c763"
      },
      "source": [
        "### 📂 Step 4: Mounts your ```.mgb``` file for one file in TrainFiles."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "783c14b1-26b0-49a4-ba6d-58cda5fad195",
      "metadata": {
        "id": "783c14b1-26b0-49a4-ba6d-58cda5fad195",
        "outputId": "95bf16ac-38de-46ba-a564-ac0ac2803878"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "📁 Host path to `.mgb`: C:\\Users\\amyfl\\Downloads\\TestFiles\\ID_ZZWUCJ.mgb\n",
            "📁 Host directory mounted: C:\\Users\\amyfl\\Downloads\\TestFiles\n",
            "📦 Container directory will be: /data\n",
            "📄 Output FASTQ: ID_ZZWUCJ.fastq\n"
          ]
        }
      ],
      "source": [
        "notebook_dir = os.getcwd()\n",
        "\n",
        "# Pick one `.mgb` file from TrainFiles\n",
        "mgb_filename = \"ID_ZZWUCJ.mgb\"\n",
        "mgb_filename_no_mgb = mgb_filename[:-4]\n",
        "train_dir = os.path.join(os.getcwd(), \"TestFiles\")\n",
        "mgb_file_path = os.path.join(train_dir, mgb_filename)\n",
        "\n",
        "# Output location for decoded FASTQ\n",
        "output_fastq = f\"{mgb_filename_no_mgb}.fastq\"\n",
        "\n",
        "# Docker mount paths\n",
        "host_dir = train_dir                # Local directory with the `.mgb` file\n",
        "container_dir = \"/data\"             # Directory inside the container\n",
        "\n",
        "# Show paths\n",
        "print(f\"📁 Host path to `.mgb`: {mgb_file_path}\")\n",
        "print(f\"📁 Host directory mounted: {host_dir}\")\n",
        "print(f\"📦 Container directory will be: {container_dir}\")\n",
        "print(f\"📄 Output FASTQ: {output_fastq}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "409931dd-d615-456f-bef6-35e8a593b754",
      "metadata": {
        "id": "409931dd-d615-456f-bef6-35e8a593b754"
      },
      "source": [
        "### 🔍 Step 5: Decodes ```.mgb``` to .```fastq``` of that one file."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ac77f66a-a79d-4725-ae94-78c71d0f43b0",
      "metadata": {
        "id": "ac77f66a-a79d-4725-ae94-78c71d0f43b0",
        "outputId": "b8ead1aa-bd4a-49e1-aefb-28ee258d9e07"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Running: docker run --rm -v .:/work muefab/genie:latest run -f -i /work/TestFiles/ID_ZZWUCJ.mgb -o /work/TestFiles/ID_ZZWUCJ.fastq\n",
            "\n",
            "--- STDOUT ---\n",
            "\n",
            "[INFO,      0.000s, App]:    ______           _\n",
            "[INFO,      0.000s, App]:   / ____/__  ____  (_)__\n",
            "[INFO,      0.000s, App]:  / / __/ _ \\/ __ \\/ / _ \\\n",
            "[INFO,      0.000s, App]: / /_/ /  __/ / / / /  __/\n",
            "[INFO,      0.000s, App]: \\____/\\___/_/ /_/_/\\___/\n",
            "[INFO,      0.000s, App]: Command: /usr/local/bin/genie run -f -i /work/TestFiles/ID_ZZWUCJ.mgb -o /work/TestFiles/ID_ZZWUCJ.fastq \n",
            "[INFO,      0.110s, App/Run]: Input file 1: /work/TestFiles/ID_ZZWUCJ.mgb with size 5.43MiB\n",
            "[INFO,      0.146s, App/Run]: Working directory: /work/TestFiles with 327GiB available\n",
            "[INFO,      0.183s, App/Run]: Output file: /work/TestFiles/ID_ZZWUCJ.fastq with 327GiB available\n",
            "[INFO,      0.183s, App/Run]: Threads: 8 with 8 supported\n",
            "[INFO,      0.191s, Spring]: Temporary directory: /work/TestFiles/tmp.lZt2RWpa7m/\n",
            "[INFO,      0.200s, Spring]: Temporary directory: /work/TestFiles/tmp.kNFI52pKW5/\n",
            "[INFO,      0.218s, Mgb]: Found PS 0...\n",
            "[INFO,      0.379s, Mgb]: AU 0: class U, 163440 records (Global Assembly)\n",
            "[INFO,      0.379s, Mgb]: Progress: 5% of file read\n",
            "[INFO,      0.379s, Mgb]: Progress: 10% of file read\n",
            "[INFO,      0.379s, Mgb]: Progress: 15% of file read\n",
            "[INFO,      0.379s, Mgb]: Progress: 20% of file read\n",
            "[INFO,      0.379s, Mgb]: Progress: 25% of file read\n",
            "[INFO,      0.379s, Mgb]: Progress: 30% of file read\n",
            "[INFO,      0.379s, Mgb]: Progress: 35% of file read\n",
            "[INFO,      0.379s, Mgb]: Progress: 40% of file read\n",
            "[INFO,      0.379s, Mgb]: Progress: 45% of file read\n",
            "[INFO,      0.379s, Mgb]: Progress: 50% of file read\n",
            "[INFO,      0.379s, Mgb]: Progress: 55% of file read\n",
            "[INFO,      0.379s, Mgb]: Progress: 60% of file read\n",
            "[INFO,      0.379s, Mgb]: Progress: 65% of file read\n",
            "[INFO,      0.379s, Mgb]: Progress: 70% of file read\n",
            "[INFO,      0.379s, Mgb]: Progress: 75% of file read\n",
            "[INFO,      0.379s, Mgb]: Progress: 80% of file read\n",
            "[INFO,      0.379s, Mgb]: Progress: 85% of file read\n",
            "[INFO,      0.379s, Mgb]: Progress: 90% of file read\n",
            "[INFO,      0.379s, Mgb]: Progress: 95% of file read\n",
            "[INFO,     35.896s, Stats]: size-fastq-name                         sum: 10657658        \n",
            "[INFO,     35.896s, Stats]: size-fastq-quality                      sum: 20348280        \n",
            "[INFO,     35.896s, Stats]: size-fastq-sequence                     sum: 20348280        \n",
            "[INFO,     35.896s, Stats]: size-fastq-total                        sum: 51354218        \n",
            "[INFO,     35.896s, Stats]: size-zstd-mmpos-position-comp           sum: 47434           \n",
            "[INFO,     35.896s, Stats]: size-zstd-mmpos-position-raw            sum: 678080          \n",
            "[INFO,     35.896s, Stats]: size-zstd-mmpos-terminator-comp         sum: 15779           \n",
            "[INFO,     35.896s, Stats]: size-zstd-mmpos-terminator-raw          sum: 103089          \n",
            "[INFO,     35.896s, Stats]: size-zstd-mmtype-substitution-comp      sum: 12408           \n",
            "[INFO,     35.896s, Stats]: size-zstd-mmtype-substitution-raw       sum: 42380           \n",
            "[INFO,     35.896s, Stats]: size-zstd-mmtype-type-comp              sum: 20              \n",
            "[INFO,     35.896s, Stats]: size-zstd-mmtype-type-raw               sum: 42380           \n",
            "[INFO,     35.896s, Stats]: size-zstd-pair-decoding_case-comp       sum: 153             \n",
            "[INFO,     35.896s, Stats]: size-zstd-pair-decoding_case-raw        sum: 81743           \n",
            "[INFO,     35.896s, Stats]: size-zstd-pair-r1_split-comp            sum: 91              \n",
            "[INFO,     35.896s, Stats]: size-zstd-pair-r1_split-raw             sum: 368             \n",
            "[INFO,     35.896s, Stats]: size-zstd-pair-r2_split-comp            sum: 80              \n",
            "[INFO,     35.896s, Stats]: size-zstd-pair-r2_split-raw             sum: 368             \n",
            "[INFO,     35.896s, Stats]: size-zstd-pair-same_rec-comp            sum: 22592           \n",
            "[INFO,     35.896s, Stats]: size-zstd-pair-same_rec-raw             sum: 326788          \n",
            "[INFO,     35.896s, Stats]: size-zstd-pos-first-comp                sum: 444             \n",
            "[INFO,     35.896s, Stats]: size-zstd-pos-first-raw                 sum: 1307888         \n",
            "[INFO,     35.896s, Stats]: size-zstd-qv-steps_0-comp               sum: 4892091         \n",
            "[INFO,     35.896s, Stats]: size-zstd-qv-steps_0-raw                sum: 20348280        \n",
            "[INFO,     35.896s, Stats]: size-zstd-rcomp-rcomp-comp              sum: 26              \n",
            "[INFO,     35.896s, Stats]: size-zstd-rcomp-rcomp-raw               sum: 163440          \n",
            "[INFO,     35.896s, Stats]: size-zstd-rlen-rlen-comp                sum: 349             \n",
            "[INFO,     35.896s, Stats]: size-zstd-rlen-rlen-raw                 sum: 2615424         \n",
            "[INFO,     35.896s, Stats]: size-zstd-rname-comp                    sum: 691250          \n",
            "[INFO,     35.896s, Stats]: size-zstd-rname-raw                     sum: 5412076         \n",
            "[INFO,     35.896s, Stats]: size-zstd-rtype-rtype-comp              sum: 14069           \n",
            "[INFO,     35.896s, Stats]: size-zstd-rtype-rtype-raw               sum: 81767           \n",
            "[INFO,     35.896s, Stats]: size-zstd-total-comp                    sum: 5699769         \n",
            "[INFO,     35.896s, Stats]: size-zstd-total-raw                     sum: 31230238        \n",
            "[INFO,     35.896s, Stats]: size-zstd-ureads-ureads-comp            sum: 2983            \n",
            "[INFO,     35.896s, Stats]: size-zstd-ureads-ureads-raw             sum: 26167           \n",
            "[INFO,     35.896s, Stats]: time-fastq-export                       sum: 30.797000       \n",
            "[INFO,     35.896s, Stats]: time-namewriteout                       sum: 0.569000        \n",
            "[INFO,     35.896s, Stats]: time-qv-calq                            sum: 1.997000        \n",
            "[INFO,     35.896s, Stats]: time-spring-decoder                     sum: 1.115000        \n",
            "[INFO,     35.896s, Stats]: time-wallclock                          sum: 35.712000       \n",
            "[INFO,     35.896s, Stats]: time-zstd                               sum: 0.318000        \n",
            "\n"
          ]
        }
      ],
      "source": [
        "def inspect_mgb_structure(host_dir=\".\", container_dir=\"/work\", mgb_filename=mgb_filename):\n",
        "    command = [\n",
        "        \"docker\", \"run\", \"--rm\",\n",
        "        \"-v\", f\"{host_dir}:{container_dir}\",\n",
        "        \"muefab/genie:latest\", \"run\",  # ✅ Add \"run\" subcommand here\n",
        "        \"-f\",\n",
        "        \"-i\", f\"{container_dir}/TestFiles/{mgb_filename}\",\n",
        "        \"-o\", f\"{container_dir}/TestFiles/{mgb_filename_no_mgb}.fastq\"\n",
        "    ]\n",
        "    print(\"Running:\", \" \".join(command))\n",
        "    result = subprocess.run(command, capture_output=True, text=True)\n",
        "    print(\"\\n--- STDOUT ---\\n\")\n",
        "    print(result.stdout)\n",
        "    if result.stderr:\n",
        "        print(\"\\n--- STDERR ---\\n\")\n",
        "        print(result.stderr)\n",
        "\n",
        "inspect_mgb_structure()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0baf4122-bd36-44d5-ac38-19b22c04e5ed",
      "metadata": {
        "id": "0baf4122-bd36-44d5-ac38-19b22c04e5ed"
      },
      "source": [
        "### 🧬 Step 6: Load FASTQ in Python"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c1b2d7e2-678d-4b9f-a0c6-af471493c52b",
      "metadata": {
        "id": "c1b2d7e2-678d-4b9f-a0c6-af471493c52b",
        "outputId": "a21ae4fb-20dd-4890-8a2c-ede7f052457e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "🔍 Total reads: 163440\n",
            "📏 Avg read length: 124.5 bp\n",
            "🎯 Avg quality score: 33.3\n"
          ]
        }
      ],
      "source": [
        "# Safer path for Windows (forward slashes or raw string)\n",
        "fastq_path = os.path.join(os.getcwd(), train_dir, f\"{mgb_filename_no_mgb}.fastq\")\n",
        "\n",
        "# Check if the file exists before parsing\n",
        "if not os.path.exists(fastq_path):\n",
        "    print(f\"❌ FASTQ file not found at: {fastq_path}\")\n",
        "else:\n",
        "    total_reads = 0\n",
        "    read_lengths = []\n",
        "    quality_scores = []\n",
        "\n",
        "    for record in SeqIO.parse(fastq_path, \"fastq\"):\n",
        "        total_reads += 1\n",
        "        read_lengths.append(len(record.seq))\n",
        "        quality_scores.extend(record.letter_annotations[\"phred_quality\"])\n",
        "\n",
        "    print(f\"🔍 Total reads: {total_reads}\")\n",
        "    print(f\"📏 Avg read length: {sum(read_lengths)/len(read_lengths):.1f} bp\")\n",
        "    print(f\"🎯 Avg quality score: {sum(quality_scores)/len(quality_scores):.1f}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f4099a0c-9ce7-4c75-bfc6-85e2845b0646",
      "metadata": {
        "id": "f4099a0c-9ce7-4c75-bfc6-85e2845b0646",
        "outputId": "15b45547-6dd9-4521-ae82-047240c10eb5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "🧪 First 3 reads:\n",
            "\n",
            "🔹 ID: NB501656:452:H3WJWAFXY:2:11306:21744:4603\n",
            "🔹 SEQ: ATACGTAAGGACCGAGCGTTGTCCGGAATCATTGGGCGTAAAGGGTACGT...\n",
            "🔹 QUALITY: [36, 36, 36, 36, 36, 36, 36, 36, 36, 36]...\n",
            "\n",
            "🔹 ID: NB501656:452:H3WJWAFXY:2:11306:21744:4603\n",
            "🔹 SEQ: CCTGTTTGCTACCCACGCTTTCGTACCTCAGCGTCAGATAATGGCCAGAA...\n",
            "🔹 QUALITY: [36, 36, 36, 36, 36, 36, 36, 36, 36, 36]...\n",
            "\n",
            "🔹 ID: NB501656:452:H3WJWAFXY:1:11302:10166:2744\n",
            "🔹 SEQ: ATACGTAAGGACCGAGCGTTGTCCGGAATCATTGGGCGTAAAGGGTACGT...\n",
            "🔹 QUALITY: [36, 36, 36, 36, 36, 36, 36, 36, 36, 36]...\n",
            "\n"
          ]
        }
      ],
      "source": [
        "print(\"🧪 First 3 reads:\\n\")\n",
        "for i, record in enumerate(SeqIO.parse(fastq_path, \"fastq\")):\n",
        "    print(f\"🔹 ID: {record.id}\")\n",
        "    print(f\"🔹 SEQ: {record.seq[:50]}...\")  # just preview first 50 bp\n",
        "    print(f\"🔹 QUALITY: {record.letter_annotations['phred_quality'][:10]}...\\n\")\n",
        "    if i >= 2:\n",
        "        break\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8c7c1d61-e2d0-456a-bcbb-85c87a8cfd63",
      "metadata": {
        "id": "8c7c1d61-e2d0-456a-bcbb-85c87a8cfd63"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "id": "d2472b20-6b35-4b89-83da-b8df524e9557",
      "metadata": {
        "id": "d2472b20-6b35-4b89-83da-b8df524e9557"
      },
      "source": [
        "### 🧠 What MPEG-G Did (Plain English)\n",
        "\n",
        "Your `.mgb` file used the MPEG-G standard to store sequencing data efficiently. Here's what happened under the hood:\n",
        "\n",
        "- **Access Units (AUs)**: Think of these as independent blocks, like packets or video frames. Each AU can be decoded without needing the entire file.\n",
        "  \n",
        "- **Descriptor Streams**:\n",
        "  - `SEQUENCE`: These are the DNA letters (A, T, C, G...).\n",
        "  - `QUALITY`: Confidence for each base (used to assess sequencing accuracy).\n",
        "  - `READ_IDENTIFIER`: Name or ID of each read.\n",
        "\n",
        "- **Compression Techniques**:\n",
        "  - Redundancies in the reads and IDs were removed.\n",
        "  - Quality scores may have been quantized or entropy-coded.\n",
        "  - Optional reference-based compression could align reads to a known genome and store only differences.\n",
        "\n",
        "- **Output Format (`.fastq`)**:\n",
        "  - This format is standard in genomics: it includes the ID, DNA sequence, and quality scores for each read.\n",
        "\n",
        "MPEG-G is to genomics what `.mp4` is to video — a way to store large data efficiently without losing critical information."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "fc553413-28af-492b-8739-2b8e442de41d",
      "metadata": {
        "id": "fc553413-28af-492b-8739-2b8e442de41d"
      },
      "source": [
        "### 🏃 Step 7: Run steps 4 & 5"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6076ad58-cd07-436e-bd21-bcf6cc3a6f02",
      "metadata": {
        "id": "6076ad58-cd07-436e-bd21-bcf6cc3a6f02"
      },
      "outputs": [],
      "source": [
        "# Set base directories\n",
        "notebook_dir = os.getcwd()\n",
        "container_dir = \"/data\"  # This is the container's path\n",
        "\n",
        "def decode_all_mgb_in_folder(folder_name):\n",
        "    host_dir = os.path.join(notebook_dir, folder_name)\n",
        "    for mgb_filename in os.listdir(host_dir):\n",
        "        if not mgb_filename.endswith(\".mgb\"):\n",
        "            continue\n",
        "\n",
        "        mgb_filename_no_ext = os.path.splitext(mgb_filename)[0]\n",
        "        print(f\"\\n🔄 Decoding: {mgb_filename}\")\n",
        "\n",
        "        command = [\n",
        "            \"docker\", \"run\", \"--rm\",\n",
        "            \"-v\", f\"{host_dir}:{container_dir}\",\n",
        "            \"muefab/genie:latest\", \"run\",\n",
        "            \"-f\",\n",
        "            \"-i\", f\"{container_dir}/{mgb_filename}\",\n",
        "            \"-o\", f\"{container_dir}/{mgb_filename_no_ext}.fastq\"\n",
        "        ]\n",
        "\n",
        "        print(\"Running:\", \" \".join(command))\n",
        "        result = subprocess.run(command, capture_output=True, text=True)\n",
        "\n",
        "        \"\"\"\n",
        "        Caution on printing out each line as this does take up memory.\n",
        "\n",
        "        print(\"\\n--- STDOUT ---\\n\")\n",
        "        print(result.stdout)\n",
        "        if result.stderr:\n",
        "            print(\"\\n--- STDERR ---\\n\")\n",
        "            print(result.stderr)#\n",
        "\n",
        "        \"\"\""
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 📢 N.B. Split your Train and Test files into smaller sub files\n",
        "\n",
        "Decoding the mgb files is time and compute intensive, we recommend splitting the train and test files into smaller bite size chunks."
      ],
      "metadata": {
        "id": "yj_2L-vwlekL"
      },
      "id": "yj_2L-vwlekL"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c325462b-a464-4605-b59f-ac6c228fe53c",
      "metadata": {
        "id": "c325462b-a464-4605-b59f-ac6c228fe53c"
      },
      "outputs": [],
      "source": [
        "decode_all_mgb_in_folder(\"TrainFiles\")\n",
        "decode_all_mgb_in_folder(\"TestFiles\")"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.4"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}